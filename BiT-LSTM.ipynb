{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.f_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.c_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.o_gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.time_gate = nn.Linear(1, hidden_size)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev, time_delta):\n",
    "        combined = torch.cat((x, h_prev), dim=1)\n",
    "        i = torch.sigmoid(self.i_gate(combined))\n",
    "        f = torch.sigmoid(self.f_gate(combined))\n",
    "        o = torch.sigmoid(self.o_gate(combined))\n",
    "        c_tilde = torch.tanh(self.c_gate(combined))\n",
    "        time_delta = time_delta.unsqueeze(1)\n",
    "        time_factor = torch.sigmoid(self.time_gate(time_delta))\n",
    "        c_prev_decayed = c_prev * time_factor\n",
    "        c = f * c_prev_decayed + i * c_tilde\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "class BiTLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size, lstm_num_layers, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.tlstm = TLSTMCell(lstm_hidden_size * 2, lstm_hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(lstm_hidden_size)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x, time_deltas):\n",
    "        bilstm_out, _ = self.bilstm(x)\n",
    "        h = torch.zeros(x.size(0), self.tlstm.hidden_size).to(x.device)\n",
    "        c = torch.zeros(x.size(0), self.tlstm.hidden_size).to(x.device)\n",
    "        for t in range(x.size(1)):\n",
    "            delta_t = time_deltas[:, t] if t < x.size(1) - 1 else torch.zeros(x.size(0)).to(x.device)\n",
    "            h, c = self.tlstm(bilstm_out[:, t, :], h, c, delta_t)\n",
    "        if h.size(0) > 1:\n",
    "            h = self.bn(h)\n",
    "        out = self.dropout(h)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
